# Multi-Agent Research Assistant

A sophisticated research tool that uses multiple AI agents to analyze topics through a structured workflow. The system provides human-in-the-loop feedback capabilities and generates comprehensive reports with streaming real-time updates.

## ğŸŒŸ Features

- **Multi-Agent Analysis**: 5 specialized agents work in sequence (Researcher â†’ Generator â†’ Evaluator â†’ Proposer â†’ Aggregator)
- **Human-in-the-Loop**: Provide feedback between iterations to refine results
- **Real-time Streaming**: Watch analysis unfold in real-time with streaming responses
- **Multiple LLM Support**: Use Gemini API or local LLMs (Ollama/OpenAI-compatible)
- **File Upload**: Include context files to enhance analysis
- **Export Options**: Save results as Markdown or JSON
- **Session Sharing**: Share analysis sessions via URL links
- **Auto-save**: Automatic session persistence and restore
- **Dark/Light Mode**: Toggle between themes
- **Prompt Editing**: Customize agent prompts for specific needs

## ğŸš€ Quick Start

### Prerequisites
- Node.js (v16 or higher)
- Gemini API key (for cloud AI) OR local LLM setup (optional)

### Installation

1. **Clone and install dependencies:**
   ```bash
   git clone <repository-url>
   cd multi-agent-research-assistant
   npm install
   ```

2. **Set up your API key:**
   - Create `.env.local` file in the root directory
   - Add your Gemini API key:
     ```
     API_KEY=your_gemini_api_key_here
     ```

3. **Run the application:**
   ```bash
   npm run dev
   ```

4. **Open your browser:**
   - Navigate to `http://localhost:5173`
   - Start analyzing!

## ğŸ“– How to Use

### Basic Workflow

1. **Choose Your LLM Provider**
   - **Gemini API**: Default option, requires API key
   - **Local LLM**: Use Ollama, LM Studio, or OpenAI-compatible endpoint

2. **Enter Your Research Topic**
   - Be specific for better results
   - Examples: "The impact of renewable energy on job markets", "Blockchain adoption in healthcare"

3. **Upload Context Files (Optional)**
   - Drag & drop or click to upload text files
   - Supports: .txt, .md, .csv, and other text formats
   - Files provide additional context for agents

4. **Start Analysis**
   - Click "Start Analysis" 
   - Watch the 6-step process unfold in real-time

5. **Review Results**
   - Read agent outputs as they stream
   - Check stylized facts and questions
   - Review the final aggregated report

6. **Provide Feedback (Optional)**
   - After completion, add feedback in the feedback panel
   - Click "Submit Revision" to run iteration 2
   - Agents will refine their analysis based on your input

### The 6-Step Analysis Process

```
1. ğŸ” Research      â†’ Gathers background information
2. âš¡ Generate      â†’ Creates initial analysis
3. ğŸ” Evaluate      â†’ Critically reviews the analysis
4. ğŸ’¡ Propose       â†’ Suggests improvements
5. ğŸ“Š Aggregate     â†’ Synthesizes everything into final report
6. âœ¨ Stylize       â†’ Extracts key facts and questions
```

### Advanced Features

#### **Session Management**
- **Auto-save**: Sessions automatically save to localStorage
- **Restore**: Reload your last session on app startup
- **Share**: Copy shareable links to distribute your analysis
- **Export**: Save as Markdown (.md) or JSON (.json)

#### **Prompt Customization**
- Click the âœï¸ edit icon on any agent card
- Modify prompts to suit your specific needs
- Test and improve prompts with the built-in tester
- Prompts persist across sessions

#### **Local LLM Setup**
1. **Install Ollama** (recommended):
   ```bash
   # macOS/Linux
   curl -fsSL https://ollama.ai/install.sh | sh
   
   # Pull a model
   ollama pull qwen3:4b
   ```

2. **Configure in the app**:
   - Select "Local LLM" provider
   - URL: `http://localhost:11434/v1/chat/completions`
   - Model: `qwen3:4b` (automatically configured)

3. **Alternative setups**:
   - LM Studio: Use their OpenAI-compatible endpoint
   - Oobabooga: Configure with OpenAI extension
   - Any OpenAI-compatible API

## ğŸ¯ Use Cases

### **Academic Research**
- Literature reviews and synthesis
- Topic exploration and hypothesis generation
- Critical analysis of research areas
- Identifying research gaps and questions

### **Business Analysis**
- Market research and competitive analysis
- Strategy development and evaluation
- Risk assessment and opportunity identification
- Policy analysis and recommendations

### **Content Creation**
- Blog post research and outline generation
- Report writing with structured analysis
- Fact-checking and source verification
- Educational material development

### **Personal Learning**
- Deep dives into complex topics
- Structured learning with Q&A generation
- Skill development research
- Career planning and industry analysis

## ğŸ’¡ Tips for Best Results

### **Topic Formulation**
- âœ… **Good**: "The role of artificial intelligence in transforming customer service in retail"
- âŒ **Avoid**: "AI" (too broad)
- âœ… **Good**: "Environmental impact of electric vehicle adoption in urban areas"
- âŒ **Avoid**: "Cars and environment" (too vague)

### **Using Context Files**
- Include relevant documents, data, or research papers
- Keep files focused and relevant to your topic
- Use text formats for best parsing (.txt, .md, .csv)
- Multiple perspectives enhance analysis quality

### **Effective Feedback**
- Be specific about what to improve or change
- Point out missing perspectives or areas to explore
- Ask for additional analysis on specific subtopics
- Request different frameworks or approaches

### **Prompt Optimization**
- Test prompts with the built-in prompt tester
- Include specific output format requirements
- Add domain expertise instructions
- Specify analysis frameworks or methodologies

## ğŸ”§ Troubleshooting

### **Common Issues**

**"Model not found" error with local LLM:**
- Ensure your local LLM is running (`ollama serve`)
- Check the model name matches what you've pulled
- Verify the endpoint URL is correct

**Slow or no streaming:**
- Check your internet connection
- For local LLMs, ensure sufficient system resources
- Try refreshing the page and restarting

**API key errors:**
- Verify your Gemini API key is correctly set
- Check the `.env.local` file format
- Ensure the API key has proper permissions

**Dark mode not working:**
- Try a hard refresh (Ctrl+F5 or Cmd+Shift+R)
- Clear browser cache
- Check if browser extensions are interfering

### **Performance Optimization**

**For better speed:**
- Use local LLMs for faster processing
- Reduce file upload sizes
- Close other browser tabs during analysis
- Use wired internet connection for stability

**For better quality:**
- Provide more context through file uploads
- Use specific, well-crafted topics
- Iterate with targeted feedback
- Customize prompts for your domain

## ğŸ› ï¸ Development

### **Tech Stack**
- **Frontend**: React 19, TypeScript, Tailwind CSS
- **AI Integration**: Gemini API, OpenAI-compatible endpoints
- **Build Tool**: Vite
- **Deployment**: Static hosting compatible

### **Project Structure**
```
â”œâ”€â”€ components/          # UI components
â”‚   â”œâ”€â”€ AgentCard.tsx   # Individual agent displays
â”‚   â”œâ”€â”€ ControlPanel.tsx # Main controls
â”‚   â”œâ”€â”€ ResultsPanel.tsx # Facts & questions
â”‚   â””â”€â”€ ...
â”œâ”€â”€ services/           # AI service integrations
â”œâ”€â”€ types.ts           # TypeScript definitions
â”œâ”€â”€ prompts.ts         # Default agent prompts
â””â”€â”€ App.tsx           # Main application
```

### **Customization**
- Modify prompts in `prompts.ts`
- Add new agent types in `types.ts`
- Extend UI components as needed
- Configure additional LLM providers

## ğŸ“„ License

This project is open source and available under the MIT License.

## ğŸ¤ Contributing

Contributions are welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## ğŸ“ Support

For questions, issues, or feature requests:
- Open an issue on GitHub
- Check the troubleshooting section above
- Review the tips for optimal usage

---

**Happy Researching!** ğŸ‰